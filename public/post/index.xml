<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Haoyu Dong</title>
    <link>http://localhost:1313/post/</link>
      <atom:link href="http://localhost:1313/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Sun, 29 Dec 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu7729264130191091259.png</url>
      <title>Posts</title>
      <link>http://localhost:1313/post/</link>
    </image>
    
    <item>
      <title>I received A&#43; in my Deep Learning course!</title>
      <link>http://localhost:1313/post/my-post/</link>
      <pubDate>Sun, 29 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/my-post/</guid>
      <description>&lt;p&gt;I won A+ grade in &lt;strong&gt;ECBM4040 NEURAL NETWRKS &amp;amp; DEEP LEARNING&lt;/strong&gt; advised by &lt;strong&gt;Prof.Zoran Kostic&lt;/strong&gt; in Columbia.&lt;/p&gt;
&lt;p&gt;Exploring deep learning has been an enriching experience, offering valuable insights and practical applications as I built different models from scratch. Throughout the course, I had the opportunity to work on various challenges, including a Kaggle competition on CNN image classification, where I achieved a &lt;strong&gt;top-three&lt;/strong&gt; accuracy in the class. I also received a score of &lt;strong&gt;95/100&lt;/strong&gt; on my final project, which further deepened my understanding of the subject. Ultimately, I completed the course with an &lt;strong&gt;A+&lt;/strong&gt;, and Iâ€™m excited to continue exploring this dynamic field.&lt;/p&gt;
&lt;p&gt;My final project is about &lt;strong&gt;Kolmogorov-Arnold Representation Theorem based Neural Network&lt;/strong&gt;, and the final report is available &lt;a href=&#34;E4040.2024Fall.KANY.report.hd2573.jx2598.yk3108.pdf&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt; while code is in my &lt;a href=&#34;https://github.com/kozmojor/Tensorflow-Implementation-of-KAN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;github&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>RoPerformer: Rotary Positional Embedding Mechanism on Sparse Attention Architecture</title>
      <link>http://localhost:1313/post/exploring-transformer-models/</link>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/exploring-transformer-models/</guid>
      <description>&lt;p&gt;This project is advised by &lt;strong&gt;Prof.Krzysztof Choromanski&lt;/strong&gt; as final project for course &lt;strong&gt;IEOR6617 Machine Learning and High-Dimensional Data&lt;/strong&gt; in Columbia, which focuses on the &lt;strong&gt;rotary positional embedding mechanism&lt;/strong&gt; on both classical &lt;strong&gt;Transformer&lt;/strong&gt; and &lt;strong&gt;Sparse-Attention based Transformer(Performer)&lt;/strong&gt;. We conducted thorough experiments involving both models and several &lt;strong&gt;SOTA&lt;/strong&gt; positional embedding mechanisms on &lt;strong&gt;CIFAR100&lt;/strong&gt; dataset and gave detailed analysis in &lt;a href=&#34;RoPerformer.pdf&#34;&gt;&lt;strong&gt;final report&lt;/strong&gt;&lt;/a&gt; on our results.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Maximum Coentropy Criterion based Kalman Filtering</title>
      <link>http://localhost:1313/post/maximum-coentropy-criterion-based-kalman-filtering/</link>
      <pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/maximum-coentropy-criterion-based-kalman-filtering/</guid>
      <description>&lt;p&gt;This project is the thesis for my B.S degree in Control &amp;amp; Automation in Xian Jiaotong University, advised by &lt;strong&gt;Prof.Guanghua Zhang&lt;/strong&gt;. The work is mainly about the improvement of &lt;strong&gt;Traditional Kalman Filter(KF)&lt;/strong&gt; under &lt;strong&gt;Non-Gaussian noise&lt;/strong&gt;. In the project, two kinds of non-gaussian noise are introduced as example: Mixture Gaussian Noise &amp;amp; Shot Noise, and Maximum Coentropy Criterion serves as the core of improved KF(MCCKF). Both mathematical derivation &amp;amp; coding experiments show the outstanding performance of MCCKF under given noises compared with classical KF. The Chinese version of the paper can be found &lt;a href=&#34;Maximum-Coentropy-Criterion-based-Kalman-Filtering.pdf&#34;&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
